{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#introduction","title":"Introduction","text":"<p>ripflow provides a framework to parallelize data analysis tasks in arbitrary data streams.</p> <p>The package contains the Python classes to build a middle layer application that reads data from various sources and applies arbitrary analysis pipelines onto the data using overlapping worker processes. The processed data is then published via programmable sink connectors.</p>"},{"location":"basic-usage/","title":"Basic Usage","text":"<p>A ripflow pipeline is meant to be inserted into data streams where it can be used to apply arbitrary analysis pipelines to the data. The data is read from a source connector, processed by a user-defined analysis pipeline and published via a sink connector.</p> <p>A basic middle layer analysis server can look like the following:</p> <pre><code>from ripflow import Ripflow\nfrom ripflow.connectors.source import PydoocsSourceConnector\nfrom ripflow.connectors.sink import ZMQSinkConnector\nfrom ripflow.serializers import JsonSerializer\nfrom ripflow.analyzers import ImageProjector\n\n# Define connector for incoming data (here pydoocs zmq)\nsource_connector = PydoocsSourceConnector(\n    source_properties=[\"DATA/SOURCE/ADDRESS\"])\n# Define analysis pipeline, here simulate a 200 ms latency\nanalyzer = ImageProjector(fake_load=0.2)\n# Define output connector. This one serializes the data\n# as a json string and sends each property via a ZMQ PUB socket\nsink_connector = ZMQSinkConnector(port=1337, serializer=JsonSerializer())\n\n# Create server instance\nserver = Ripflow(\n        source_connector=source_connector,\n        sink_connector=sink_connector,\n        analyzer=analyzer,\n        n_workers=10)\n\n# Run event loop.\nserver.event_loop()\n</code></pre> <p>In the example above, the incoming image data stream is pulled from a DOOCS server via a <code>PydoocsSourceConnector</code>. The data is distributed in round-robin fashion between 10 workers, which apply the <code>ImageProjector</code> analysis pipeline to the data. The result is then serialized as a json string and published via a ZMQ PUB socket.</p> <p>Internally the server uses ZeroMQ to communicate between the processes that handle grabbing, analyzing and sending the data. The general architecture looks like this:</p> <p></p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#with-pip","title":"with pip","text":"<p>The ripflow package is published as a Python package and can be installed with pip: <pre><code>pip install ripflow\n</code></pre></p>"},{"location":"getting-started/#with-poetry","title":"with poetry","text":"<p>You can also add ripflow to a project that is managed with poetry: <pre><code>poetry add ripflow\n</code></pre></p>"},{"location":"getting-started/#from-source","title":"from source","text":"<p>To install the package from source, clone the repository and install the package with poetry: <pre><code>poetry install\n</code></pre></p>"},{"location":"api/middle-layer-analyzer/","title":"MiddleLayerAnalyzer","text":"<p><code>ripflow.middle_layer_analyzer.MiddleLayerAnalyzer</code></p> <p>The <code>MiddleLayerAnalyzer</code> class is a Python object that provides an interface for analyzing incoming data from a <code>SourceConnector</code> and processing it using a provided Analyzer object. The processed data is then sent to an external system via a <code>SinkConnector</code>. The class is designed to work in parallel using multiple worker processes and is responsible for managing worker and sender processes using ZeroMQ sockets.</p> <p>The class has the following parameters:</p> <ul> <li><code>source_connector</code> : SourceConnector object that provides incoming data to the analyzer.</li> <li><code>sink_connector</code> : SinkConnector object that sends the processed data to an external system.</li> <li><code>analyzer</code> : Analyzer object that processes the incoming data, that inherits from the <code>BaseAnalyzer</code> base class.</li> <li><code>n_workers</code> : integer, number of worker processes to use for parallel processing. The default value is 2.</li> <li><code>log_file_path</code> : string, path to the log file. The default value is \"server.log\".</li> <li><code>log_level</code> : string, level of logging to use. The default value is \"INFO\".</li> </ul> <p>The class provides the following method for starting the main event loop:</p> <ul> <li><code>event_loop(background=False)</code> : starts the main event loop for processing incoming data using worker and sender processes. If background is False, the producer routine is launched and the process runs in the current thread and therefore blocks the code. If background is True, the producer routine is launched in a separate process and the method returns immediately.</li> </ul> <p>The class uses ZeroMQ sockets for interprocess communication, allowing for efficient and scalable parallel processing of incoming data. Overall, the MiddleLayerAnalyzer class is a flexible and powerful tool for analyzing and processing large amounts of data in parallel.</p>"},{"location":"api/sink-connectors/","title":"Sink Connector API","text":"<p>Sink connectors handle the outgoing stream of the processed data. They are responsible for publishing the processed data to the desired destination.</p>"},{"location":"api/sink-connectors/#sinkconnector","title":"SinkConnector","text":"<p><code>ripflow.connectors.sink.SinkConnector</code></p> <p>This object is an abstract class that defines the basis for all sink connectors. It provides the following methods:</p> <ul> <li><code>connect_subprocess(idx)</code> - This method is called when the connector is first initialized. It is responsible for setting up the connection to the destination system and performing any other initialization tasks. The <code>idx</code>argument is the index of the data array that is generated by the workers. For each data entry an individual sender process is spawned.</li> <li><code>send(data)</code> - This method is called whenever new data is made available by the worker processes. The data is provided as bytes.</li> </ul> <p>The <code>SinkConnector</code> requires a <code>Serializer</code> object that defines the transformation of the internal data format into the messages that are sent out by the <code>SinkConnector</code>. The <code>Serializer</code> object is provided as the <code>serializer</code> argument to the <code>SinkConnector</code> constructor.</p> <p>Custom sink connectors should inherit from this class and implement the <code>connect_subprocess()</code> and <code>send()</code> methods.</p> <p>Example:</p> <pre><code>from typing import List, Dict\nfrom ripflow.connectors.sink import SinkConnector\nfrom ripflow.serializers import Serializer\nimport time\n\nclass FileSinkConnector(SinkConnector):\n    def __init__(self, serializer: Serializer, filename: str) -&gt; None:\n        self.filename = filename\n        self.serializer = serializer\n\n    def connect_subprocess(self) -&gt; None:\n        self.file = open(self.filename, \"r\")\n\n    def send(self, data: bytes) -&gt; None:\n        self.file.write(data)\n        self.file.flush()\n</code></pre>"},{"location":"api/sink-connectors/#zmqsinkconnector","title":"ZmqSinkConnector","text":"<p><code>ripflow.connectors.sink.ZmqSinkConnector</code></p> <p>This sink connector is used to publish data via the ZeroMQ protocol. Specifically, this sink connector makes use of a zmq pub socket. The connector is configured using the following parameters:</p> <ul> <li><code>port</code> - The port to publish the data on.</li> <li><code>serializer</code> - A <code>Serializer</code> object that defines the transformation of the internal data format into the messages that are sent as bytes over the zmq socket.</li> </ul> <p>Example:</p> <pre><code>from ripflow.serializers import JsonSerializer\nfrom ripflow.connectors.sink import ZmqSinkConnector\n\nsink_connector = ZMQSinkConnector(port=1337, serializer=JsonSerializer())\n</code></pre>"},{"location":"api/source-connectors/","title":"Source Connector API","text":"<p>Source connectors deal with the incoming data from the source system. They are responsible for reading the data from the source system and providing it to the worker processes. The source connector API is designed to be flexible and allow for easy implementation of different types of data sources.</p>"},{"location":"api/source-connectors/#sourceconnector","title":"SourceConnector","text":"<p><code>ripflow.connectors.source.SourceConnector</code></p> <p>This object is an abstract class that defines the basis for all source connectors. It provides the following methods:</p> <ul> <li><code>connect()</code> - This method is called when the connector is first initialized. It is responsible for setting up the connection to the source system and performing any other initialization tasks.</li> <li><code>get_data()</code>- This method is used to poll new data from the source system. The function should be blocking until new data is available. The function should return a list of dictionaries.</li> </ul> <p>A custom source connector should inherit from this class and implement the <code>connect()</code> and <code>get_data()</code> methods. Example:</p> <pre><code>from typing import List, Dict\nfrom ripflow.connectors.source import SourceConnector\nimport time\nimport json\n\nclass JsonFileSourceConnector(SourceConnector):\n    def __init__(self, filename: str) -&gt; None:\n        self.filename = filename\n\n    def connect(self) -&gt; None:\n        self.file = open(self.filename, \"r\")\n\n    def get_data(self) -&gt; List[Dict]:\n        while True:\n            line = self.file.readline()\n            if not line:\n                # File is empty, wait for new entries\n                time.sleep(1)\n            else:\n                return [json.loads(line)]\n</code></pre>"},{"location":"api/source-connectors/#pydoocssourceconnector","title":"PydoocsSourceConnector","text":"<p><code>ripflow.connectors.source.PydoocsSourceConnector</code></p> <p>This source connector is used to read data from the DOOCS system. It utilizes the DOOCS zmq interface to read data from zmq capable DOOCS properties. The connector is configured using the following parameters:</p> <ul> <li>source_properties - A list of DOOCS properties to read from.</li> <li>timeout - Timeout in seconds. If no data is available within the timeout, the connector will raise a TimeoutError.</li> </ul> <p>Example:</p> <pre><code>source_connector = PydoocsSourceConnector(\n    source_properties=[\"FLASH.LASER/HIDRAPP1.CAM/PA_OUT.34.FF/IMAGE_EXT_ZMQ\"])\n</code></pre>"}]}